---
title: "Chocolate Chip Cookies"
execute:
  error: true
author: "Ty Hansen"
date: 2026/02/03
output: html_document
---

## Reading In the Data
First, read in the CSV data of cookie ingredients.
Make sure that your end-result data has appropriate types for each column - these should match the types provided in the documentation in the README.md file.
```{r}
cookie<-read.csv("choc_chip_cookie_ingredients.csv")
library(reticulate)
```
```{python}
import pandas as pd
cookies = pd.read_csv('choc_chip_cookie_ingredients.csv')
```

## Exploratory Data Analysis
Exploratory data analysis is the process of getting familiar with your dataset. To get started, [this blog post](https://www.mrdbourke.com/a-gentle-introduction-to-exploratory-data-analysis/) provides a nice checklist to get you thinking:

> 1.  What question(s) are you trying to solve (or prove wrong)?
> 2.  What kind of data do you have and how do you treat different types?
> 3.  What's missing from the data and how do you deal with it?
> 4.  Where are the outliers and why should you care about them?
> 5.  How can you add, change or remove features to get more out of your data?

### Generating Questions
Generate at least 5 questions you might explore using this database of cookie ingredients.

1. What is the distribution of ratings across all recipes?
2. Are there any missing values, if so how many?
3. How does the number of ingredients in a recipe relate to its rating?
4. What are the most commonly used ingredients in high rated recipes?
5. Do different measurement quantities correlate with recipe ratings?

### Skimming the Data
One thing we often want to do during EDA is to examine the quality of the data - are there missing values? What quirks might exist in the dataset?

The `skimr` package in R, and the similar `skimpy` package in python (which has a much better name, in my opinion), can help provide visual summaries of the data. 

Install both packages, and read the package documentation ([R](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html), [Python](https://pypi.org/project/skimpy/)).

[Part 1] Use each package and generate summaries of your data that require the use of at least some non-default options in each package's `skim` function.
```{r}
library(skimr)
skim(cookie)
```
```{python}
from skimpy import skim
skim(cookies)
```

[Part 2] Write 1-2 sentences about what you can tell from each summary display you generate. Did you discover anything new about the data?

The summary shows that the dataset contains 1990 rows with 209 unique recipes and 68 unique ingredients. The Rating variable has 1010 missing values (51% complete rate), and among rated recipes, the ratings are quite high with a mean of 0.81 and most values clustered between 0.75 and 0.91. The histogram shows most quantities are relatively small.
### Generating Tables
Another useful technique for exploratory data analysis is to generate summary tables. 

You may want to use the `dplyr` package in R `group_by` or `count` functions), as well as the `groupby` and `count` methods in Pandas. [Python example](https://sparkbyexamples.com/pandas/pandas-groupby-count-examples/), [R example](https://dplyr.tidyverse.org/reference/count.html)

[Part 1] Using R and Python, generate a table that shows what **proportion** of recipes contain each type of ingredient, for the most common 20 ingredients.
```{r}
unique_combos <- unique(cookie[c("Ingredient", "Recipe_Index")])
recipes_per_ingredient <- table(unique_combos$Ingredient)
total_recipes <- length(unique(cookie$Recipe_Index))
proportions <- recipes_per_ingredient / total_recipes

sort(proportions, decreasing = TRUE)[1:20]
```

```{python}
unique_combos = cookies[['Ingredient', 'Recipe_Index']].drop_duplicates()
recipes_per_ingredient = unique_combos['Ingredient'].value_counts()
total_recipes = cookies['Recipe_Index'].nunique()
proportions = recipes_per_ingredient / total_recipes
proportions.sort_values(ascending=False).head(20)
```

[Part 2] Print out a character string that lists all of the ingredients that do not appear in at least 20 recipes.
```{r}
rare_ingredients <- names(recipes_per_ingredient[recipes_per_ingredient < 20])
paste(rare_ingredients, collapse = ", ")
```

```{python}
rare_ingredients = recipes_per_ingredient[recipes_per_ingredient < 20].index.tolist()
', '.join(rare_ingredients)
```

### Visualization
Using whatever plotting system you are comfortable with in R or python, see if you can create a couple of useful exploratory data visualizations which address one of the questions you wrote above - or another question which you've come up with as you've worked on this assignment.

[Part 1] Create at least one plot (it doesn't have to be pretty) that showcases an interesting facet of the data.
```{r}
library(ggplot2)
ggplot(cookie, aes(x=Quantity, y=Rating)) + 
  geom_point(alpha=0.5) +
  labs(x="Quantity", y="Rating", title="Relationship between Quantity and Rating")
```

```{python}
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.scatter(cookies['Quantity'], cookies['Rating'], alpha=0.5)
plt.xlabel('Quantity')
plt.ylabel('Rating')
plt.title('Relationship between Quantity and Rating')
plt.show() 
```

[Part 2] Write 2-3 sentences about what you can learn from that plot and what directions you might want to investigate from here.

The scatterplot reveals that there is no clear linear relationship between ingredient quantity and recipe rating, with most ratings clustered in the 0.75-1.0 range regardless of quantity. The majority of ingredients used are in small quantities (0-5 units), with only a few outliers requiring larger amounts up to ~48 units. Moving forward, it would be more productive to investigate which specific ingredients appear most in high rated recipes, or to examine whether the total number of ingredients per recipe has any relationship with rating.
